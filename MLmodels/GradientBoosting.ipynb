{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A price prediction model: Gradient Boosting Regressor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data Simulation\n",
    "First, we simulate a dataset that represents loans, including various features and a target variable 'Price' which we aim to predict. The features include:\n",
    "\n",
    "Moneyness, Interest Rates, Par Rates: Continuous variables representing financial metrics.\n",
    "Loan Amount: The total amount of the loan.\n",
    "Age: The age of the borrower.\n",
    "Duration: The term of the loan in years.\n",
    "Credit Score: A numerical representation of the borrower's creditworthiness.\n",
    "Employment Status: Categorical variable indicating whether the borrower is employed or unemployed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Data Preprocessing\n",
    "Since machine learning models require numerical input, we convert categorical variables into a numerical format using label encoding. This process converts \"Employed\" and \"Unemployed\" into 0 and 1, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Model Training\n",
    "We split our dataset into a training set and a test set, using 80% of the data for training and 20% for testing. Then, we initialize a Gradient Boosting Regressor with specified hyperparameters and train it on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Moneyness</th>\n",
       "      <th>Interest_Rates</th>\n",
       "      <th>Par_Rates</th>\n",
       "      <th>Loan_Amount</th>\n",
       "      <th>Age</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Credit_Score</th>\n",
       "      <th>Employment_Status</th>\n",
       "      <th>Predicted_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.185465</td>\n",
       "      <td>4.112627</td>\n",
       "      <td>4.087393</td>\n",
       "      <td>35332</td>\n",
       "      <td>39</td>\n",
       "      <td>21</td>\n",
       "      <td>717</td>\n",
       "      <td>0</td>\n",
       "      <td>3219.467621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.086076</td>\n",
       "      <td>3.115580</td>\n",
       "      <td>5.196634</td>\n",
       "      <td>21723</td>\n",
       "      <td>56</td>\n",
       "      <td>11</td>\n",
       "      <td>780</td>\n",
       "      <td>1</td>\n",
       "      <td>1182.288765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Moneyness  Interest_Rates  Par_Rates  Loan_Amount  Age  Duration  \\\n",
       "8   1.185465        4.112627   4.087393        35332   39        21   \n",
       "1   1.086076        3.115580   5.196634        21723   56        11   \n",
       "\n",
       "   Credit_Score  Employment_Status  Predicted_Price  \n",
       "8           717                  0      3219.467621  \n",
       "1           780                  1      1182.288765  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Simulate dataset\n",
    "np.random.seed(0)  # For reproducibility\n",
    "data = {\n",
    "    \"Moneyness\": np.random.uniform(0.8, 1.2, 10),\n",
    "    \"Interest_Rates\": np.random.uniform(1, 5, 10),\n",
    "    \"Par_Rates\": np.random.uniform(2, 6, 10),\n",
    "    \"Loan_Amount\": np.random.randint(10000, 50000, 10),\n",
    "    \"Age\": np.random.randint(25, 60, 10),\n",
    "    \"Duration\": np.random.randint(1, 30, 10),\n",
    "    \"Credit_Score\": np.random.randint(600, 800, 10),\n",
    "    \"Employment_Status\": np.random.choice([\"Employed\", \"Unemployed\"], 10),\n",
    "    \"Price\": np.random.uniform(1000, 5000, 10)  # This will be our target variable\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Encode categorical data\n",
    "le = LabelEncoder()\n",
    "df['Employment_Status'] = le.fit_transform(df['Employment_Status'])\n",
    "\n",
    "# Splitting dataset into features (X) and target (y)\n",
    "X = df.drop(\"Price\", axis=1)\n",
    "y = df[\"Price\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train gradient boosting regressor\n",
    "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict prices\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Append predictions to the test set for output\n",
    "X_test['Predicted_Price'] = predictions\n",
    "\n",
    "# Display the test set with predicted prices\n",
    "X_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Prediction\n",
    "We predict prices using the test set. This step involves using the features from the test set to generate price predictions based on the patterns learned during training.\n",
    "\n",
    "5. Saving Predictions\n",
    "Finally, we simulate predictions for the entire dataset for demonstration purposes (as we only made predictions for the test set). We then save the original dataset along with the predicted prices into a new CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Python Practice files\\\\ML models\\\\Gradient Boosting\\\\predicted_loan_prices.csv'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simulating predictions for the entire dataset for demonstration\n",
    "full_predictions = model.predict(X)\n",
    "\n",
    "# Add predicted prices to the original dataset\n",
    "df['Predicted_Price'] = full_predictions\n",
    "\n",
    "# Save to new CSV file\n",
    "csv_file_path = 'D:\\Python Practice files\\ML models\\Gradient Boosting\\predicted_loan_prices.csv'\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "csv_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code Snippets and Their Functions:\n",
    "Data Simulation: np.random functions are used to generate random data for our dataset.\n",
    "Label Encoding: LabelEncoder() from sklearn.preprocessing encodes categorical variables.\n",
    "Splitting Dataset: train_test_split splits the data into training and testing sets.\n",
    "Model Initialization and Training: GradientBoostingRegressor() initializes the model, and .fit() trains it.\n",
    "Prediction: .predict() is used to make predictions on the test set.\n",
    "Saving to CSV: to_csv() saves the DataFrame to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R² score for our model on the test set is approximately:  -14.141136238735262\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Compute R² score\n",
    "r2 = r2_score(y_test, predictions)\n",
    "\n",
    "r2\n",
    "\n",
    "print(\"The R² score for our model on the test set is approximately: \", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Accuracy:\n",
    "To evaluate the model's performance, we typically use metrics such as Mean Absolute Error (MAE), Mean Squared Error (MSE), or R² (coefficient of determination). Let's compute the R² score for our model on the test set, which indicates how well the model predictions approximate the true values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The model performs significantly worse than a simple mean baseline.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final verdict based on the R² score\n",
    "if r2 > 0.75:\n",
    "    verdict = \"The model has strong predictive performance.\"\n",
    "elif r2 > 0.5:\n",
    "    verdict = \"The model has moderate predictive performance.\"\n",
    "elif r2 > 0:\n",
    "    verdict = \"The model has weak predictive performance.\"\n",
    "else:\n",
    "    verdict = \"The model performs significantly worse than a simple mean baseline.\"\n",
    "\n",
    "verdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improved Model: In Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV R²: -0.1012 ± 0.1846\n",
      "R² score: -0.27335827618834396\n",
      "The model performs significantly worse than a simple mean baseline.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Generate a larger dataset\n",
    "np.random.seed(0)  # Ensure reproducibility\n",
    "data = {\n",
    "    \"Moneyness\": np.random.uniform(0.8, 1.2, 100),\n",
    "    \"Interest_Rates\": np.random.uniform(1, 5, 100),\n",
    "    \"Par_Rates\": np.random.uniform(2, 6, 100),\n",
    "    \"Loan_Amount\": np.random.randint(10000, 50000, 100),\n",
    "    \"Age\": np.random.randint(25, 60, 100),\n",
    "    \"Duration\": np.random.randint(1, 30, 100),\n",
    "    \"Credit_Score\": np.random.randint(600, 800, 100),\n",
    "    \"Employment_Status\": np.random.choice([\"Employed\", \"Unemployed\"], 100),\n",
    "    \"Price\": np.random.uniform(1000, 5000, 100)  # Target variable\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Preprocess data\n",
    "le = LabelEncoder()\n",
    "df['Employment_Status'] = le.fit_transform(df['Employment_Status'])\n",
    "\n",
    "X = df.drop(\"Price\", axis=1)\n",
    "y = df[\"Price\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameter tuning setup\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'max_depth': [3, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(GradientBoostingRegressor(random_state=0), param_grid, cv=5, scoring='r2')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Using cross-validation to evaluate the model\n",
    "cv_r2_scores = cross_val_score(best_model, X, y, cv=5, scoring='r2')\n",
    "print(f\"CV R²: {np.mean(cv_r2_scores):.4f} ± {np.std(cv_r2_scores):.4f}\")\n",
    "\n",
    "# Predictions and evaluation\n",
    "predictions = best_model.predict(X_test)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(f\"R² score: {r2}\")\n",
    "\n",
    "# Save the best model to a pickle file\n",
    "import pickle\n",
    "with open('best_gb_model.pickle', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "# Save predictions to CSV\n",
    "predicted_prices = best_model.predict(X)\n",
    "df['Predicted_Price'] = predicted_prices\n",
    "df.to_csv('D:/Python Practice files/ML models/Gradient Boosting/predicted_loan_prices_improved.csv', index=False)\n",
    "\n",
    "# Final Verdict\n",
    "if r2 > 0.75:\n",
    "    verdict = \"The model has strong predictive performance.\"\n",
    "elif r2 > 0.5:\n",
    "    verdict = \"The model has moderate predictive performance.\"\n",
    "elif r2 > 0:\n",
    "    verdict = \"The model has weak predictive performance.\"\n",
    "else:\n",
    "    verdict = \"The model performs significantly worse than a simple mean baseline.\"\n",
    "print(verdict)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
